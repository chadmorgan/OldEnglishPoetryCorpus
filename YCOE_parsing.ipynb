{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.3)\n",
    "matplotlib.rcParams[\"legend.framealpha\"] = 1\n",
    "matplotlib.rcParams[\"legend.frameon\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the York-Helsinki Corpus of Old English Poetry\n",
    "\n",
    "We will process the parsed YCOE corpus to extract each sentence and the corresponging POS tags. YCOE has a very extensive set of POS tags and a representation of the sentence structute- we will discard the sentence struction information and simplify the tags to a higher-order level.\n",
    "\n",
    "More information on the corpus here: http://www-users.york.ac.uk/~lang18/pcorpus.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the Old English characters æ,ð,þ\n",
    "def oe_character_sub(s):\n",
    "    s = re.sub('\\+a','æ',s)\n",
    "    s = re.sub('\\+A','Æ',s)\n",
    "    s = re.sub('\\+t','þ',s)\n",
    "    s = re.sub('\\+T','Þ',s)\n",
    "    s = re.sub('\\+d','ð',s)\n",
    "    s = re.sub('\\+D','Ð',s)\n",
    "    s = re.sub('\\$','',s)\n",
    "    s = s.lower()\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts what we need from each sentence\n",
    "def extract_tagged_tokens(ppcme_string):\n",
    "    ppcme_string = re.sub(' +',' ',re.sub('\\n|\\t','',ppcme_string))\n",
    "    ppcme_nodes = re.split('\\(|\\)',ppcme_string)\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for node in ppcme_nodes:\n",
    "        node_split = re.sub(' $','',node).split(' ')\n",
    "        if len(node_split)==2 \\\n",
    "        and node_split[0]!='ID' \\\n",
    "        and node_split[0]!='CODE' \\\n",
    "        and node_split[1][0]!=\"*\" \\\n",
    "        and node_split[1]!=\"0\" \\\n",
    "        and node_split[1] not in set([',','.','!',';',':','?']):\n",
    "            tokens += [oe_character_sub(node_split[1])]\n",
    "            tags += [node_split[0]]\n",
    "    if(len(tokens)>0):\n",
    "        return((tokens,tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_pos_tagset(tag):\n",
    "    # default tag\n",
    "    simple_tag = 'XXX'\n",
    "    # remove case tag\n",
    "    tag = tag.split('^')[0]\n",
    "    # remove negation and particle tags\n",
    "    if re.search('\\+',tag):\n",
    "        tag = tag.split('+')[1]\n",
    "    if tag[0] in set(['B','H','V','T']):\n",
    "        simple_tag = 'VRB'\n",
    "    elif tag[0:2] == 'AX' or tag[0]=='M':\n",
    "        simple_tag = 'AUX'\n",
    "    elif tag in set(['N','NPR']):\n",
    "        simple_tag = 'NOUN'\n",
    "    elif tag in set(['PRO','PRO$','WPRO']):\n",
    "        simple_tag = 'PRONOUN'\n",
    "    elif tag == 'P':\n",
    "        simple_tag = 'PREP'\n",
    "    elif tag in set(['ADJ','WADJ']):\n",
    "        simple_tag = 'ADJ'\n",
    "    elif tag in set(['Q','NUM']):\n",
    "        simple_tag = 'NUM'\n",
    "    elif tag in set(['ADV','WADV']):\n",
    "        simple_tag = 'ADV'\n",
    "    elif tag in set(['CONJ','WQ','C']):\n",
    "        simple_tag = 'CONJ'\n",
    "    elif tag == 'D':\n",
    "        simple_tag = 'DET'\n",
    "    elif tag == 'NEG':\n",
    "        simple_tag = 'NEG'\n",
    "    return(simple_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_tokens = []\n",
    "poem_tags = []\n",
    "for l in check_blocks:\n",
    "    parse_block = extract_tagged_tokens(l)\n",
    "    if parse_block:\n",
    "        block_tokens = []\n",
    "        block_tags = []        \n",
    "        for i in range(len(parse_block[0])):\n",
    "            token = parse_block[0][i]\n",
    "            tag = parse_block[1][i]\n",
    "            if token not in set(['.',',','!',':',';','full-stop']):\n",
    "                block_tokens += [token]\n",
    "                tag_basic = simplify_pos_tagset(tag)\n",
    "                block_tags += [tag_basic]\n",
    "        poem_tokens += [block_tokens]            \n",
    "        poem_tags += [block_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ADV^T', 'MDPI', 'VB', 'N^G', 'N^A', 'N^G', 'N^A', 'CONJ', 'PRO$', 'N^A', 'N^A', 'N^G', 'P', 'PRO^N', 'N^G', 'Q^G', 'ADJ^N', 'NPR^N', 'N^A', 'VBDI'], ['PRO^N', 'ADV^T', 'VBDI', 'N^G', 'N^D', 'N^A', 'P', 'N^D', 'ADJ^N', 'N^N'], ['ADV^T', 'N^A', 'N^G', 'N^N', 'ADJ^N', 'NPR^N', 'ADV^T', 'VBDI', 'N^D', 'N^A', 'N^N', 'ADJ^N'], ['P', 'D^D', 'N^D', 'NEG+Q^N', 'BEPI', 'ADJ^N', 'P', 'PRO^D', 'N^N', 'BEPS', 'TO', 'RP+VB^D', 'P', 'PRO$', 'N^D', 'WPRO^N', 'PRO$', 'N^D', 'ADJ^G', 'CONJ', 'ADJ^G', 'P', 'N^D', 'VBN', 'BEPS'], ['VBDI', 'PRO^A', 'NPR^N', 'ADJ^N'], ['ADV^T', 'PRO^N', 'MDD', 'P', 'N^A', 'VB', 'ADJ^N', 'P', 'N^A'], ['X'], ['PRO^N', 'ADJ^A', 'N^A', 'N^G', 'N^A'], ['VB', 'PRO^N', 'NEG', 'MDD'], ['VBDI', 'PRO^A', 'N^N', 'Q^A', 'ADV']]\n"
     ]
    }
   ],
   "source": [
    "print(poem_tags[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ADV', 'AUX', 'VRB', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'CONJ', 'PRONOUN', 'NOUN', 'NOUN', 'NOUN', 'PREP', 'PRONOUN', 'NOUN', 'NUM', 'ADJ', 'NOUN', 'NOUN', 'VRB'], ['PRONOUN', 'ADV', 'VRB', 'NOUN', 'NOUN', 'NOUN', 'PREP', 'NOUN', 'ADJ', 'NOUN'], ['ADV', 'NOUN', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'ADV', 'VRB', 'NOUN', 'NOUN', 'NOUN', 'ADJ'], ['PREP', 'DET', 'NOUN', 'NUM', 'VRB', 'ADJ', 'PREP', 'PRONOUN', 'NOUN', 'VRB', 'VRB', 'VRB', 'PREP', 'PRONOUN', 'NOUN', 'PRONOUN', 'PRONOUN', 'NOUN', 'ADJ', 'CONJ', 'ADJ', 'PREP', 'NOUN', 'VRB', 'VRB'], ['VRB', 'PRONOUN', 'NOUN', 'ADJ'], ['ADV', 'PRONOUN', 'AUX', 'PREP', 'NOUN', 'VRB', 'ADJ', 'PREP', 'NOUN'], ['XXX'], ['PRONOUN', 'ADJ', 'NOUN', 'NOUN', 'NOUN'], ['VRB', 'PRONOUN', 'NEG', 'AUX'], ['VRB', 'PRONOUN', 'NOUN', 'NUM', 'ADV']]\n"
     ]
    }
   ],
   "source": [
    "print(poem_tags[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to all files and collect sentences across all\n",
    "contents = os.listdir(path)\n",
    "\n",
    "poem_tokens = []\n",
    "poem_tags = []\n",
    "poem_sentence_mapping = []\n",
    "for poem in contents:\n",
    "    poem_raw = open(path+'/'+poem).read()\n",
    "    poem_blocks = poem_raw.split('( ')\n",
    "    for l in poem_blocks:\n",
    "        parse_block = extract_tagged_tokens(l)\n",
    "        if parse_block:\n",
    "            block_tokens = []\n",
    "            block_tags = []        \n",
    "            for i in range(len(parse_block[0])):\n",
    "                token = parse_block[0][i]\n",
    "                tag = parse_block[1][i]\n",
    "                if token not in set(['.',',','!',':',';','full-stop']):\n",
    "                    if len(tag)>0:\n",
    "                        block_tokens += [token]\n",
    "                        tag_basic = simplify_pos_tagset(tag)\n",
    "                        block_tags += [tag_basic]\n",
    "            poem_tokens += [block_tokens]            \n",
    "            poem_tags += [block_tags]\n",
    "            poem_sentence_mapping += [poem[2:].split(\".\")[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6333\n",
      "6333\n"
     ]
    }
   ],
   "source": [
    "print(len(poem_tokens))\n",
    "print(len(poem_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hwæt'], ['we', 'gefrunan', 'on', 'fyrndagum', 'twelfe', 'under', 'tunglum', 'tireadige', 'hæleð', 'þeodnes', 'þegnas'], ['no', 'hira', 'þrym', 'alæg', 'camprædenne', 'þonne', 'cumbol', 'hneotan', 'syððan', 'hie', 'gedældon', 'swa', 'him', 'dryhten', 'sylf', 'heofona', 'heahcyning', 'hlyt', 'getæhte']]\n"
     ]
    }
   ],
   "source": [
    "print(poem_tokens[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PRONOUN'], ['PRONOUN', 'VRB', 'PREP', 'NOUN', 'NUM', 'PREP', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'NOUN'], ['ADV', 'PRONOUN', 'NOUN', 'VRB', 'NOUN', 'PREP', 'NOUN', 'VRB', 'PREP', 'PRONOUN', 'VRB', 'PREP', 'PRONOUN', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'VRB']]\n"
     ]
    }
   ],
   "source": [
    "print(poem_tags[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = {}\n",
    "tag_set = set()\n",
    "\n",
    "for sentence_tags in poem_tags:\n",
    "    for tag in sentence_tags:\n",
    "        if tag not in tag_set:\n",
    "            tag_set.add(tag)\n",
    "            tag_dict[tag] = 1\n",
    "        else:\n",
    "            tag_dict[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2)\n",
      "Top tags by frequency:\n",
      "        tag   freq\n",
      "0      NOUN  22982\n",
      "1       VRB  12335\n",
      "2      PREP   6793\n",
      "3       ADJ   6535\n",
      "4   PRONOUN   5805\n",
      "5       ADV   5400\n",
      "6      CONJ   3634\n",
      "7       DET   3421\n",
      "8       NUM   2033\n",
      "9       AUX   1468\n",
      "10      NEG    552\n",
      "11      XXX    500\n"
     ]
    }
   ],
   "source": [
    "tag_count = pd.DataFrame.from_dict(tag_dict,orient='index').reset_index()\n",
    "tag_count.columns = ['tag','freq']\n",
    "tag_count = tag_count.sort_values('freq',ascending=False)\\\n",
    "    .reset_index(drop=True)\n",
    "print(tag_count.shape)\n",
    "print(\"Top tags by frequency:\")\n",
    "print(tag_count.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'andrea': 453,\n",
       " 'beowul': 1696,\n",
       " 'brunan': 26,\n",
       " 'christ': 430,\n",
       " 'cynew': 937,\n",
       " 'dream': 112,\n",
       " 'exeter': 676,\n",
       " 'exodus': 318,\n",
       " 'genesi': 446,\n",
       " 'kentis': 70,\n",
       " 'metboe': 340,\n",
       " 'northu': 31,\n",
       " 'phoeni': 259,\n",
       " 'riddle': 539}"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((x,poem_sentence_mapping.count(x)) for x in set(poem_sentence_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split of sentences stratified by source\n",
    "ycoe_x_train, ycoe_x_test, \\\n",
    "ycoe_y_train, ycoe_y_test, \\\n",
    "ycoe_src_train, ycoe_src_test = \\\n",
    "train_test_split(poem_tokens,poem_tags,poem_sentence_mapping,\\\n",
    "                 test_size=0.2,stratify=poem_sentence_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'andrea': 362,\n",
       " 'beowul': 1357,\n",
       " 'brunan': 21,\n",
       " 'christ': 344,\n",
       " 'cynew': 749,\n",
       " 'dream': 90,\n",
       " 'exeter': 541,\n",
       " 'exodus': 254,\n",
       " 'genesi': 357,\n",
       " 'kentis': 56,\n",
       " 'metboe': 272,\n",
       " 'northu': 25,\n",
       " 'phoeni': 207,\n",
       " 'riddle': 431}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((x,ycoe_src_train.count(x)) for x in set(ycoe_src_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
