{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the York-Helsinki Corpus of Old English Poetry\n",
    "\n",
    "We will process the parsed YCOE corpus to extract each sentence and the corresponging POS tags. YCOE has a very extensive set of POS tags and a representation of the sentence structure- we will discard the sentence structure information and simplify the tags to a higher-order level.\n",
    "\n",
    "More information on the corpus here: http://www-users.york.ac.uk/~lang18/pcorpus.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.3)\n",
    "matplotlib.rcParams[\"legend.framealpha\"] = 1\n",
    "matplotlib.rcParams[\"legend.frameon\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show corpus contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coandrea.psd', 'cobeowul.psd', 'cobrunan.psd', 'cochrist.psd', 'cocynew.psd', 'codream.psd', 'coexeter.psd', 'coexodus.psd', 'cogenesi.psd', 'cokentis.psd', 'cometboe.psd', 'conorthu.psd', 'cophoeni.psd', 'coriddle.psd']\n"
     ]
    }
   ],
   "source": [
    "# show poems available in corpus\n",
    "contents = os.listdir(path)\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPCME2 structure\n",
    "See the beginning of the poem \"The Dream of the Rood\"\n",
    "\n",
    "    hwæt! ic swefna cyst secgan wylle,\n",
    "    hwæt me gemætte to midre nihte\n",
    "    syðþan reordberend reste wunedon.\n",
    "\n",
    "The block below shows the representation of this sentence in the YCOE corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( (CODE <P_61>))\n",
      "( (CODE <COM:THE_DREAM_OF_THE_ROOD>))\n",
      "( (CODE <R_1>))\n",
      "( (INTJP (INTJ Hw+at)\n",
      "\t (. .)) (ID codream,61.1.4))\n",
      "( (IP-MAT (NP-NOM (PRO^N Ic))\n",
      "\t  (NP-ACC (NP-GEN (N^G swefna))\n",
      "\t  (ADJ^A cyst)\n",
      "\t  (CP-QUE-PRN *ICH*-1))\n",
      "\t  (VB secgan)\n",
      "\t  (MDP wylle)\n",
      "\t  (, ,)\n",
      "\t  (CP-QUE-PRN-1 (WNP-NOM-2 (WPRO^N $hw+at))\n",
      "\t\t(C 0)\n",
      "\t\t(IP-SUB (NP-NOM *T*-2)\n",
      "\t\t(NP-DAT (PRO^D me))\n",
      "\t\t(VBD gem+atte)\n",
      "\t\t(PP (P to)\n",
      "\t\t    (NP-DAT (ADJ^D midre) (N^D nihte)))\n",
      "\t\t(, ,)\n",
      "\t\t(PP (P sy+d+tan)\n",
      "\t\t    (CP-ADV (C 0)\n",
      "\t\t\t    (IP-SUB (NP-NOM (N^N reordberend))\n",
      "\t\t\t    (NP-DAT-ADT (N^D reste))\n",
      "\t\t\t    (VBDI wunedon))))))\n",
      "\t  (. .)) (ID codream,61.1.5))\n",
      "( (CODE <R_4>))\n"
     ]
    }
   ],
   "source": [
    "# show example line from the raw file for Dream of the Rood\n",
    "poem = 'codream.psd'\n",
    "poem_raw = open(path+'/'+poem).readlines()\n",
    "for l in poem_raw[0:27]:\n",
    "    print(re.sub('\\n','',re.sub('\\t\\t','\\t',l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and reformat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the Old English characters æ,ð,þ\n",
    "def oe_character_sub(s):\n",
    "    s = re.sub('\\+a','æ',s)\n",
    "    s = re.sub('\\+A','Æ',s)\n",
    "    s = re.sub('\\+t','þ',s)\n",
    "    s = re.sub('\\+T','Þ',s)\n",
    "    s = re.sub('\\+d','ð',s)\n",
    "    s = re.sub('\\+D','Ð',s)\n",
    "    s = re.sub('\\$','',s)\n",
    "    s = s.lower()\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts what we need from each sentence\n",
    "def extract_tagged_tokens(ppcme_string):\n",
    "    ppcme_string = re.sub(' +',' ',re.sub('\\n|\\t','',ppcme_string))\n",
    "    ppcme_nodes = re.split('\\(|\\)',ppcme_string)\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for node in ppcme_nodes:\n",
    "        node_split = re.sub(' $','',node).split(' ')\n",
    "        if len(node_split)==2 \\\n",
    "        and node_split[0]!='ID' \\\n",
    "        and node_split[0]!='CODE' \\\n",
    "        and node_split[1][0]!=\"*\" \\\n",
    "        and node_split[1]!=\"0\" \\\n",
    "        and node_split[1] not in set([',','.','!',';',':','?']):\n",
    "            tokens += [oe_character_sub(node_split[1])]\n",
    "            tags += [node_split[0]]\n",
    "    if(len(tokens)>0):\n",
    "        return((tokens,tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_case(tag):\n",
    "    if re.search('\\^',tag):\n",
    "        case = tag.split('^')[1]\n",
    "\n",
    "        # Nominative case (subject)\n",
    "        if case == 'N':\n",
    "            case = 'NOM'\n",
    "        # Accusative case (direct object)\n",
    "        elif case == 'A':\n",
    "            case = 'ACC'\n",
    "        # Genitive case (possession)\n",
    "        elif case == 'G':\n",
    "            case = 'GEN'\n",
    "        # Dative and instrumental cases (indirect object)\n",
    "        elif case in set(['D','I']):\n",
    "            case = 'DAT'\n",
    "        # Temporal case (specifying a time)\n",
    "        elif case == 'T':\n",
    "            case = 'TEMP'\n",
    "        # Set minor, rare cases as default \"x\"\n",
    "        else:\n",
    "            case = 'X'\n",
    "    # If there is no case (for verbs, prep, etc.), set as \"x\"\n",
    "    else:\n",
    "        case = 'X'\n",
    "    return(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_pos_tagset(tag):\n",
    "\n",
    "    # remove case tag\n",
    "    tag = tag.split('^')[0]\n",
    "    # remove negation and particle tags\n",
    "    if re.search('\\+',tag):\n",
    "        tag = tag.split('+')[1]\n",
    "    \n",
    "    # Verbs tags (B=Be, H=Have, V = other Verbs)\n",
    "    if tag[0] in set(['B','H','V']):\n",
    "        simple_tag = 'VRB'\n",
    "    # Auxillary Verbs (M = Modal, T = \"To\" inifinitive)\n",
    "    elif tag[0:2] == 'AX' or tag[0] in set(['M','T']):\n",
    "        simple_tag = 'AUX'\n",
    "    # Nouns (N = common noun, NPR = proper noun)\n",
    "    elif tag in set(['N','NPR']):\n",
    "        simple_tag = 'NOUN'\n",
    "    # Pronouns (PRO$ = possesive, WPRO = Wh- pronoun)\n",
    "    elif tag in set(['PRO','PRO$','WPRO']):\n",
    "        simple_tag = 'PRON'\n",
    "    # Prepositions\n",
    "    elif tag == 'P':\n",
    "        simple_tag = 'PREP'\n",
    "    # Abjectives\n",
    "    elif tag in set(['ADJ','WADJ']):\n",
    "        simple_tag = 'ADJ'\n",
    "    # Numerals and quantifiers\n",
    "    elif tag in set(['Q','NUM']):\n",
    "        simple_tag = 'NUM'\n",
    "    # Adverbs\n",
    "    elif tag in set(['ADV','WADV']):\n",
    "        simple_tag = 'ADV'\n",
    "    # Conjunctions (WQ = Whether, C = Complimentizer)\n",
    "    elif tag in set(['CONJ','WQ','C']):\n",
    "        simple_tag = 'CONJ'\n",
    "    # Determiners\n",
    "    elif tag == 'D':\n",
    "        simple_tag = 'DET'\n",
    "    # Negation\n",
    "    elif tag == 'NEG':\n",
    "        simple_tag = 'NEG'\n",
    "    else:\n",
    "        # default tag for anything not falling in the categories above\n",
    "        simple_tag = 'X'    \n",
    "        \n",
    "    return(simple_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to all files and collect sentences across all\n",
    "poem_tokens = []\n",
    "poem_tags = []\n",
    "poem_case = []\n",
    "poem_sentence_mapping = []\n",
    "for poem in contents:\n",
    "    poem_raw = open(path+'/'+poem).read()\n",
    "    poem_blocks = poem_raw.split('( ')\n",
    "    for l in poem_blocks:\n",
    "        parse_block = extract_tagged_tokens(l)\n",
    "        if parse_block:\n",
    "            block_tokens = []\n",
    "            block_tags = []       \n",
    "            block_case = []\n",
    "            for i in range(len(parse_block[0])):\n",
    "                token = parse_block[0][i]\n",
    "                tag = parse_block[1][i]\n",
    "                if token not in set(['.',',','!',':',';','full-stop']):\n",
    "                    if len(tag)>0:\n",
    "                        block_tokens += [token]\n",
    "                        tag_basic = simplify_pos_tagset(tag)\n",
    "                        case = extract_case(tag)\n",
    "                        block_tags += [tag_basic]\n",
    "                        block_case += [case]\n",
    "            poem_tokens += [block_tokens]            \n",
    "            poem_tags += [block_tags]\n",
    "            poem_case += [block_case] \n",
    "            poem_sentence_mapping += [poem[2:].split(\".\")[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6333\n",
      "6333\n",
      "6333\n"
     ]
    }
   ],
   "source": [
    "print(len(poem_tokens))\n",
    "print(len(poem_tags))\n",
    "print(len(poem_case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hwæt'], ['we', 'gefrunan', 'on', 'fyrndagum', 'twelfe', 'under', 'tunglum', 'tireadige', 'hæleð', 'þeodnes', 'þegnas'], ['no', 'hira', 'þrym', 'alæg', 'camprædenne', 'þonne', 'cumbol', 'hneotan', 'syððan', 'hie', 'gedældon', 'swa', 'him', 'dryhten', 'sylf', 'heofona', 'heahcyning', 'hlyt', 'getæhte']]\n"
     ]
    }
   ],
   "source": [
    "print(poem_tokens[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PRON'], ['PRON', 'VRB', 'PREP', 'NOUN', 'NUM', 'PREP', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'NOUN'], ['ADV', 'PRON', 'NOUN', 'VRB', 'NOUN', 'PREP', 'NOUN', 'VRB', 'PREP', 'PRON', 'VRB', 'PREP', 'PRON', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'VRB']]\n"
     ]
    }
   ],
   "source": [
    "print(poem_tags[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['X'], ['NOM', 'X', 'X', 'DAT', 'ACC', 'X', 'DAT', 'ACC', 'ACC', 'GEN', 'ACC'], ['X', 'X', 'NOM', 'X', 'DAT', 'X', 'NOM', 'X', 'X', 'NOM', 'X', 'X', 'DAT', 'NOM', 'NOM', 'GEN', 'NOM', 'ACC', 'X']]\n"
     ]
    }
   ],
   "source": [
    "print(poem_case[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_dict = {}\n",
    "tag_set = set()\n",
    "\n",
    "for sentence_tags in poem_tags:\n",
    "    for tag in sentence_tags:\n",
    "        if tag not in tag_set:\n",
    "            tag_set.add(tag)\n",
    "            tag_dict[tag] = 1\n",
    "        else:\n",
    "            tag_dict[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2)\n",
      "Top tags by frequency:\n",
      "     tag   freq\n",
      "0   NOUN  22982\n",
      "1    VRB  12282\n",
      "2   PREP   6793\n",
      "3    ADJ   6535\n",
      "4   PRON   5805\n",
      "5    ADV   5400\n",
      "6   CONJ   3634\n",
      "7    DET   3421\n",
      "8    NUM   2033\n",
      "9    AUX   1521\n",
      "10   NEG    552\n",
      "11     X    500\n"
     ]
    }
   ],
   "source": [
    "tag_count = pd.DataFrame.from_dict(tag_dict,orient='index').reset_index()\n",
    "tag_count.columns = ['tag','freq']\n",
    "tag_count = tag_count.sort_values('freq',ascending=False)\\\n",
    "    .reset_index(drop=True)\n",
    "print(tag_count.shape)\n",
    "print(\"Top tags by frequency:\")\n",
    "print(tag_count.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case_dict = {}\n",
    "case_set = set()\n",
    "\n",
    "for sentence_case in poem_case:\n",
    "    for case in sentence_case:\n",
    "        if case not in case_set:\n",
    "            case_set.add(case)\n",
    "            case_dict[case] = 1\n",
    "        else:\n",
    "            case_dict[case] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "Top cases by frequency:\n",
      "   case   freq\n",
      "0     X  28460\n",
      "1   NOM  15102\n",
      "2   DAT   9738\n",
      "3   ACC   9628\n",
      "4   GEN   6245\n",
      "5  TEMP   2285\n"
     ]
    }
   ],
   "source": [
    "case_count = pd.DataFrame.from_dict(case_dict,orient='index').reset_index()\n",
    "case_count.columns = ['case','freq']\n",
    "case_count = case_count.sort_values('freq',ascending=False)\\\n",
    "    .reset_index(drop=True)\n",
    "print(case_count.shape)\n",
    "print(\"Top cases by frequency:\")\n",
    "print(case_count.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'andrea': 453,\n",
       " 'beowul': 1696,\n",
       " 'brunan': 26,\n",
       " 'christ': 430,\n",
       " 'cynew': 937,\n",
       " 'dream': 112,\n",
       " 'exeter': 676,\n",
       " 'exodus': 318,\n",
       " 'genesi': 446,\n",
       " 'kentis': 70,\n",
       " 'metboe': 340,\n",
       " 'northu': 31,\n",
       " 'phoeni': 259,\n",
       " 'riddle': 539}"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((x,poem_sentence_mapping.count(x)) for x in set(poem_sentence_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split of sentences stratified by source\n",
    "ycoe_token_train, ycoe_token_test, \\\n",
    "ycoe_pos_train, ycoe_pos_test, \\\n",
    "ycoe_case_train, ycoe_case_test, \\\n",
    "ycoe_src_train, ycoe_src_test = \\\n",
    "train_test_split(poem_tokens,poem_tags,poem_case,poem_sentence_mapping, \\\n",
    "                 test_size=0.2,stratify=poem_sentence_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'andrea': 91,\n",
       " 'beowul': 339,\n",
       " 'brunan': 5,\n",
       " 'christ': 86,\n",
       " 'cynew': 188,\n",
       " 'dream': 22,\n",
       " 'exeter': 135,\n",
       " 'exodus': 64,\n",
       " 'genesi': 89,\n",
       " 'kentis': 14,\n",
       " 'metboe': 68,\n",
       " 'northu': 6,\n",
       " 'phoeni': 52,\n",
       " 'riddle': 108}"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((x,ycoe_src_test.count(x)) for x in set(ycoe_src_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
